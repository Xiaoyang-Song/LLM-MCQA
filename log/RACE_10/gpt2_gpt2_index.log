================================================================================
Experiment Configuration
================================================================================
Dataset: RACE-10
Model Family: gpt2
Model Version: gpt2
Answer Mode: index
================================================================================
Experiment Appendix
================================================================================
>> QUESTION #1     | Ground Truth: 0 | Answer: 2 | ✘
-- Log Inverse-Perplexity: [-7.6995, -7.078, -6.6723, -6.9903]
>> QUESTION #2     | Ground Truth: 3 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-7.936, -9.1119, -8.1296, -8.9068]
>> QUESTION #3     | Ground Truth: 0 | Answer: 3 | ✘
-- Log Inverse-Perplexity: [-9.201, -8.7139, -8.0126, -7.8022]
>> QUESTION #4     | Ground Truth: 3 | Answer: 3 | ✔
-- Log Inverse-Perplexity: [-8.3771, -7.942, -7.4691, -6.9121]
>> QUESTION #5     | Ground Truth: 0 | Answer: 3 | ✘
-- Log Inverse-Perplexity: [-10.0463, -9.1952, -8.6516, -8.3679]
>> QUESTION #6     | Ground Truth: 3 | Answer: 2 | ✘
-- Log Inverse-Perplexity: [-9.4997, -7.7761, -7.2429, -7.3491]
>> QUESTION #7     | Ground Truth: 2 | Answer: 2 | ✔
-- Log Inverse-Perplexity: [-7.3981, -6.9857, -6.0332, -6.5738]
>> QUESTION #8     | Ground Truth: 1 | Answer: 3 | ✘
-- Log Inverse-Perplexity: [-11.4291, -7.8839, -7.5067, -7.2746]
>> QUESTION #9     | Ground Truth: 1 | Answer: 2 | ✘
-- Log Inverse-Perplexity: [-8.3469, -7.2445, -7.1462, -7.2826]
>> QUESTION #10    | Ground Truth: 2 | Answer: 1 | ✘
-- Log Inverse-Perplexity: [-9.2722, -7.8328, -7.9679, -8.6569]
================================================================================
MCQA Accuracy: 20.00%
================================================================================
