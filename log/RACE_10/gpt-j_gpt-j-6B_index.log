================================================================================
Experiment Configuration
================================================================================
Dataset: RACE-10
Model Family: gpt-j
Model Version: EleutherAI/gpt-j-6B
Answer Mode: index
================================================================================
Experiment Appendix
================================================================================
>> QUESTION #1     | Ground Truth: 0 | Answer: 0 | ✔
-- Log Inverse-Perplexity: [-6.2309, -7.3063, -8.0726, -8.4009]
>> QUESTION #2     | Ground Truth: 3 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-7.7358, -9.2365, -9.546, -10.0216]
>> QUESTION #3     | Ground Truth: 0 | Answer: 0 | ✔
-- Log Inverse-Perplexity: [-6.6858, -9.2381, -9.4885, -8.2956]
>> QUESTION #4     | Ground Truth: 3 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-6.7395, -7.6285, -8.8629, -9.1024]
>> QUESTION #5     | Ground Truth: 0 | Answer: 0 | ✔
-- Log Inverse-Perplexity: [-6.1584, -6.8972, -8.8195, -9.0354]
>> QUESTION #6     | Ground Truth: 3 | Answer: 1 | ✘
-- Log Inverse-Perplexity: [-6.7411, -6.073, -7.8255, -7.9185]
>> QUESTION #7     | Ground Truth: 2 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-5.5338, -7.4046, -7.4766, -8.8123]
>> QUESTION #8     | Ground Truth: 1 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-6.0715, -6.6789, -7.4381, -7.8761]
>> QUESTION #9     | Ground Truth: 1 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-6.8431, -8.1482, -9.1864, -8.7171]
>> QUESTION #10    | Ground Truth: 2 | Answer: 0 | ✘
-- Log Inverse-Perplexity: [-6.8419, -7.3343, -9.0658, -8.8512]
================================================================================
MCQA Accuracy: 30.00%
================================================================================
