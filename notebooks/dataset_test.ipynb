{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from dataset.utils import *\n",
    "from dataset.datasets import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COSMOS-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_info = get_dataset_info('cosmos')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function load_mini_rm at 0x7ff84e7703a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset race (/Users/xiaoyangsong/Desktop/LLM-MCQA/notebooks/hf_cache/race/middle/0.1.0/5839ff74a429622f5f20cca69c5fcf0e87ac6d5fd2777c42b948000684829f7b)\n",
      "Found cached dataset race (/Users/xiaoyangsong/Desktop/LLM-MCQA/notebooks/hf_cache/race/middle/0.1.0/5839ff74a429622f5f20cca69c5fcf0e87ac6d5fd2777c42b948000684829f7b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'list'> | length: 500\n",
      "['We should go to school on foot or by bike.', 'We should use plastic  bags when we go shopping.', 'We should use both sides of the paper to write.', \"We should plant more trees to protect the animals' living.\"]\n"
     ]
    }
   ],
   "source": [
    "dset_info = get_dataset_info('mini_rm')\n",
    "print(dset_info)\n",
    "dataset = load_mini_rm(0, False, 500)\n",
    "print(f\"type: {type(dataset)} | length: {len(dataset)}\")\n",
    "data = dataset[40]\n",
    "# print(data.parts)\n",
    "print(data.choices)\n",
    "# print(data.answer_idx)\n",
    "# print(data.task)\n",
    "# print(data.exemplars)\n",
    "\n",
    "# print(data.get_natural_prompt())\n",
    "# print(data.get_brown_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We should plant more trees to protect the animals' living.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from models.utils import *\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2', cache_dir=HF_CACHE_DIR_NAME)\n",
    "choice = dataset[40].choices[3]\n",
    "print(choice)\n",
    "tokens = tokenizer(\": \" + choice, return_tensors=\"pt\", add_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
